{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunkumarsr/LearnPythonWithMithun/blob/master/LVC_7_Python_Web_Scrapping_MCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Web Scrapping"
      ],
      "metadata": {
        "id": "uz1uMN_MHIEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Content:**\n",
        "1.   HTML Basics\n",
        "\n",
        "1.   Request Module\n",
        "\n",
        "2.   Web Scraping Using BeautifulSoup\n",
        "\n",
        "1.   Scrape URLs and Email IDs from Web\n",
        "\n",
        "2.   Scraping Images\n",
        "\n",
        "1.   Scraping Data on Page Load\n",
        "\n",
        "2.   Creating datset from web page\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GDBy70F-TwmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Web scraping** is the process of collecting and parsing raw data from the Web.Collecting data from websites using an automated process is known as web scraping"
      ],
      "metadata": {
        "id": "NK7iIHTOBo07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Web scraping** is the process of extracting data from websites, usually done by automated software. The extracted data can be in the form of text, images, or other types of files, and is used to build databases or perform analysis.\n",
        "\n",
        " **Web scraping** is widely used for various purposes, such as data mining, data analysis, price comparison, sentiment analysis, and much more."
      ],
      "metadata": {
        "id": "u_h5LMsfSzAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here are many libraries available for web scraping in different programming languages. Some of the most popular ones are:\n",
        "\n",
        "\n",
        "1.   Requests-HTML (Python)\n",
        "\n",
        "2.   Beautiful Soup (Python)\n",
        "1.   Scrapy (Python)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-MPKeq21TJGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basics of HTML**"
      ],
      "metadata": {
        "id": "YvCKY4ksvpBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile index.html\n",
        "<html>\n",
        "  <head>\n",
        "    <title>Title of the Page</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <div id=\"base\">\n",
        "      <a href=\"#\">Link</a>\n",
        "      <p>Paragraph</p>\n",
        "    </div>\n",
        "    <table class=\"tbl\">\n",
        "      <tr>\n",
        "        <th>Column 1</th>\n",
        "        <th>Column 2</th>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td class=\"data\">Row 1 Data 1</td>\n",
        "        <td class=\"data\">Row 1 Data 2</td>\n",
        "      </tr>\n",
        "      <tr>\n",
        "        <td class=\"data\">Row 2 Data 1</td>\n",
        "        <td class=\"data\">Row 2 Data 2</td>\n",
        "      </tr>\n",
        "    </table>\n",
        "  </body>\n",
        "</html>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCFbUQ_rs2US",
        "outputId": "23e75807-9f74-4db2-b0c8-33ba8dbfe98d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requests Module**\n",
        "\n",
        "Requests library is used for making HTTP requests to a specific URL and returns the response."
      ],
      "metadata": {
        "id": "qzucstr4LZAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requests-HTML is a Python library for parsing HTML and XML documents and extracting data from them. It works by sending HTTP requests to retrieve the HTML content of a web page, and then parsing the content to extract the data of interest."
      ],
      "metadata": {
        "id": "Rh_EH_YMWwNa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGxuCeihHDJj",
        "outputId": "698d6bff-00b5-4981-de9f-dc09f8c89e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract content of HTML page using requests library"
      ],
      "metadata": {
        "id": "-YSLTaeYY-jK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GET method is used to retrieve information from the given server using a given URI."
      ],
      "metadata": {
        "id": "GCBrm0kBMWGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " it returns a response. This Response object in terms of python is returned by requests.method()"
      ],
      "metadata": {
        "id": "-PeRK7JtMgtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the requests library:\n",
        "import requests\n",
        "\n",
        "\n",
        "# Send a GET request to the URL of the page you want to extract content from:\n",
        "response = requests.get('https://www.example.com')\n",
        "\n",
        "\n",
        "# Check the status code of the response to ensure the request was successful:\n",
        "if response.status_code == 200:\n",
        "    # The request was successful\n",
        "    # Extract the content of the page\n",
        "    page_content = response.content\n",
        "else:\n",
        "    # The request was unsuccessful\n",
        "    # Handle the error\n",
        "    pass\n",
        "# Use the content attribute of the response object to get the raw HTML content of the page:\n",
        "html_content = response.content\n",
        "\n",
        "\n",
        "# content of the page is returned as bytes,\n",
        "#so you may need to decode it to a string using the appropriate encoding, such as utf-8.\n",
        "\n",
        "html_content = response.content.decode('utf-8')\n",
        "\n",
        "print(html_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgWNWHPGY6hw",
        "outputId": "2cbf8988-dbe8-45d1-b309-b73d39f9d4a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!doctype html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Example Domain</title>\n",
            "\n",
            "    <meta charset=\"utf-8\" />\n",
            "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
            "    <style type=\"text/css\">\n",
            "    body {\n",
            "        background-color: #f0f0f2;\n",
            "        margin: 0;\n",
            "        padding: 0;\n",
            "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
            "        \n",
            "    }\n",
            "    div {\n",
            "        width: 600px;\n",
            "        margin: 5em auto;\n",
            "        padding: 2em;\n",
            "        background-color: #fdfdff;\n",
            "        border-radius: 0.5em;\n",
            "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
            "    }\n",
            "    a:link, a:visited {\n",
            "        color: #38488f;\n",
            "        text-decoration: none;\n",
            "    }\n",
            "    @media (max-width: 700px) {\n",
            "        div {\n",
            "            margin: 0 auto;\n",
            "            width: auto;\n",
            "        }\n",
            "    }\n",
            "    </style>    \n",
            "</head>\n",
            "\n",
            "<body>\n",
            "<div>\n",
            "    <h1>Example Domain</h1>\n",
            "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
            "    domain in literature without prior coordination or asking for permission.</p>\n",
            "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
            "</div>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response objects can be used to imply lots of features, methods, and functionalities."
      ],
      "metadata": {
        "id": "dzzmYD7EMn2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Making a GET request\n",
        "response = requests.get('https://www.example.com')\n",
        "\n",
        "# print request object\n",
        "print(response.url)\n",
        "\n",
        "# print status code\n",
        "print(response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykBIfumMIJCt",
        "outputId": "34983fe3-da96-4bf6-bac3-28497617ad19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.example.com/\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract elements from an HTML page using the requests_html"
      ],
      "metadata": {
        "id": "a6sL45bnkN1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests-html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rW6cQFyXXmfC",
        "outputId": "13bcdcab-321c-4944-dfb2-ea164766c4c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.32.3)\n",
            "Collecting pyquery (from requests-html)\n",
            "  Downloading pyquery-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fake-useragent (from requests-html)\n",
            "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting parse (from requests-html)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting bs4 (from requests-html)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Collecting w3lib (from requests-html)\n",
            "  Downloading w3lib-2.2.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2024.8.30)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.4.0)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.66.5)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests-html) (4.12.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (4.9.4)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests-html) (2.6)\n",
            "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
            "Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pyquery-2.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: parse, fake-useragent, appdirs, websockets, w3lib, urllib3, pyee, cssselect, pyquery, pyppeteer, bs4, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "Successfully installed appdirs-1.4.4 bs4-0.0.2 cssselect-1.2.0 fake-useragent-1.5.1 parse-1.20.2 pyee-11.1.1 pyppeteer-2.0.0 pyquery-2.0.1 requests-html-0.10.0 urllib3-1.26.20 w3lib-2.2.1 websockets-10.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              },
              "id": "3898529571144b969467f65133e03e13"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. extract elements from an HTML page using the requests_html"
      ],
      "metadata": {
        "id": "FItqH39BkY5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from requests_html import HTML, requests\n"
      ],
      "metadata": {
        "id": "327si9BYkbDw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Send a GET request to the URL of the page you want to extract elements from:"
      ],
      "metadata": {
        "id": "9V7BS9GUkrzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://www.example.com')\n"
      ],
      "metadata": {
        "id": "xIZcPZ0CkWHQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Check the status code of the response to ensure the request was successful:"
      ],
      "metadata": {
        "id": "o5fezPHmkzrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if response.status_code == 200:\n",
        "    # The request was successful\n",
        "    # Extract the content of the page\n",
        "    html_content = response.content\n",
        "else:\n",
        "    # The request was unsuccessful\n",
        "    # Handle the error\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "rRt8M5qsk29J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Use the HTML class to parse the HTML content and create an html object:"
      ],
      "metadata": {
        "id": "89xK4qZ3k7Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html = HTML(html=html_content)\n"
      ],
      "metadata": {
        "id": "ge6dnH4Ek9z5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Use the find method of the html object to search for elements with a specific tag or attribute. For example, to find all the links in the page:"
      ],
      "metadata": {
        "id": "Ql_ywr-GlAx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links = html.find('a')\n",
        "\n",
        "print(links)"
      ],
      "metadata": {
        "id": "qm_sIvPPOTNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf04abd-99bf-4cd5-8bd4-a8004a6e3551"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Element 'a' href='https://www.iana.org/domains/example'>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. To extract the text of an element, you can use the text attribute. For example, to get the text of all the links:"
      ],
      "metadata": {
        "id": "dTVzEkPrlIVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for link in links:\n",
        "  print(link.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaFs-nauZlNj",
        "outputId": "241da1d0-cde6-4384-e705-e7d4c392806e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "More information...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link_texts = [link.text for link in links]\n",
        "print(link_texts)"
      ],
      "metadata": {
        "id": "_WL1rDDAlLXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b7092b-ca04-4348-c93f-8e9612185964"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['More information...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. To extract an attribute of an element, you can use the attrs dictionary. For example, to get the href attribute of all the links:"
      ],
      "metadata": {
        "id": "y1piWKBBlOsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for attr in links:\n",
        "  print(attr.attrs['href'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko0mf3N4aNst",
        "outputId": "9dd753fe-1276-49cb-f66c-10afc3a7aa20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.iana.org/domains/example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link_hrefs = [link.attrs['href'] for link in links]\n",
        "\n",
        "print(link_hrefs)"
      ],
      "metadata": {
        "id": "zKU_1WqNlRwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f86db1-ea8c-40cd-b1ec-d58170448ba9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.iana.org/domains/example']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "html_content = response.content.decode('utf-8')\n",
        "print(html_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s26qV3k3RIWN",
        "outputId": "87560c94-5982-4cd4-c90a-baed9536d916"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!doctype html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Example Domain</title>\n",
            "\n",
            "    <meta charset=\"utf-8\" />\n",
            "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
            "    <style type=\"text/css\">\n",
            "    body {\n",
            "        background-color: #f0f0f2;\n",
            "        margin: 0;\n",
            "        padding: 0;\n",
            "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
            "        \n",
            "    }\n",
            "    div {\n",
            "        width: 600px;\n",
            "        margin: 5em auto;\n",
            "        padding: 2em;\n",
            "        background-color: #fdfdff;\n",
            "        border-radius: 0.5em;\n",
            "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
            "    }\n",
            "    a:link, a:visited {\n",
            "        color: #38488f;\n",
            "        text-decoration: none;\n",
            "    }\n",
            "    @media (max-width: 700px) {\n",
            "        div {\n",
            "            margin: 0 auto;\n",
            "            width: auto;\n",
            "        }\n",
            "    }\n",
            "    </style>    \n",
            "</head>\n",
            "\n",
            "<body>\n",
            "<div>\n",
            "    <h1>Example Domain</h1>\n",
            "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
            "    domain in literature without prior coordination or asking for permission.</p>\n",
            "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
            "</div>\n",
            "</body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the find method is used to search for all elements with the a tag div, and the text property is used to retrieve the text of each link."
      ],
      "metadata": {
        "id": "0Q5dMYybZLQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links = html.find('div')\n",
        "for link in links:\n",
        "  print(link.text)\n",
        "  print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4XNqeQvNx7s",
        "outputId": "db245de8-0711-4a55-c96f-18e18f342144"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Domain\n",
            "This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.\n",
            "More information...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from requests_html import HTML\n",
        "\n",
        "url = \"https://www.example.com\"\n",
        "\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "html = HTML(html=html_content)\n",
        "title = html.find(\"title\", first=True).text\n",
        "\n",
        "print(title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F00PwCqrW7Fa",
        "outputId": "747f89cc-58d1-4735-cc22-d659b0e1d5f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Domain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above  example, the requests.get method is used to send an HTTP GET request to the specified URL and retrieve the HTML content of the page. The content is then passed to the HTML class of the requests_html library to create an HTML object. Finally, the find method is used to search for the first occurrence of a title element in the HTML content and extract its text."
      ],
      "metadata": {
        "id": "aOf_0UWUYj38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "from requests_html import HTML\n",
        "\n",
        "url = \"https://www.example.com\"\n",
        "\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "html = HTML(html=html_content)\n",
        "p = html.find(\"p\", first=True).text\n",
        "h1=html.find(\"h1\", first=True).text\n",
        "print(p)\n",
        "print(\"\\n\")\n",
        "print(h1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeD7h6HuQJzO",
        "outputId": "1301bebf-0c77-4161-e94e-7e5bd76a9f62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.\n",
            "\n",
            "\n",
            "Example Domain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BeautifulSoup library** can extract content from an HTML page by parsing the HTML code and building a parse tree structure that can be used to search and extract information.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qKhTWdIWRqd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BeautifulSoup** is used extract information from the HTML and XML files. It provides a parse tree and the functions to navigate, search or modify this parse tree."
      ],
      "metadata": {
        "id": "16evb6akONqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1TQRXn3IOgr",
        "outputId": "cc94a40f-9b2f-47de-e8f8-a5a87f52a11e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Making a GET request\n",
        "r = requests.get('http://olympus.realpython.org/profiles/aphrodite')\n",
        "\n",
        "# check status code for response received\n",
        "# success code - 200\n",
        "print(r)\n",
        "\n",
        "# Parsing the HTML\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "print(soup.prettify())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17HJJxn0Imjj",
        "outputId": "27163833-88fb-4926-ff8e-bf4113153138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "<html>\n",
            " <head>\n",
            "  <title>\n",
            "   Profile: Aphrodite\n",
            "  </title>\n",
            " </head>\n",
            " <body bgcolor=\"yellow\">\n",
            "  <center>\n",
            "   <br/>\n",
            "   <br/>\n",
            "   <img src=\"/static/aphrodite.gif\"/>\n",
            "   <h2>\n",
            "    Name: Aphrodite\n",
            "   </h2>\n",
            "   <br/>\n",
            "   <br/>\n",
            "   Favorite animal: Dove\n",
            "   <br/>\n",
            "   <br/>\n",
            "   Favorite color: Red\n",
            "   <br/>\n",
            "   <br/>\n",
            "   Hometown: Mount Olympus\n",
            "  </center>\n",
            " </body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Making a GET request\n",
        "r = requests.get('http://olympus.realpython.org/profiles/aphrodite')\n",
        "\n",
        "# check status code for response received\n",
        "# success code - 200\n",
        "print(r)\n",
        "\n",
        "# Parsing the HTML\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "print(soup.find_all())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ-5xOHAXQmY",
        "outputId": "50941698-2bfd-4957-d6d9-9929970f99dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "[<html>\n",
            "<head>\n",
            "<title>Profile: Aphrodite</title>\n",
            "</head>\n",
            "<body bgcolor=\"yellow\">\n",
            "<center>\n",
            "<br/><br/>\n",
            "<img src=\"/static/aphrodite.gif\"/>\n",
            "<h2>Name: Aphrodite</h2>\n",
            "<br/><br/>\n",
            "Favorite animal: Dove\n",
            "<br/><br/>\n",
            "Favorite color: Red\n",
            "<br/><br/>\n",
            "Hometown: Mount Olympus\n",
            "</center>\n",
            "</body>\n",
            "</html>, <head>\n",
            "<title>Profile: Aphrodite</title>\n",
            "</head>, <title>Profile: Aphrodite</title>, <body bgcolor=\"yellow\">\n",
            "<center>\n",
            "<br/><br/>\n",
            "<img src=\"/static/aphrodite.gif\"/>\n",
            "<h2>Name: Aphrodite</h2>\n",
            "<br/><br/>\n",
            "Favorite animal: Dove\n",
            "<br/><br/>\n",
            "Favorite color: Red\n",
            "<br/><br/>\n",
            "Hometown: Mount Olympus\n",
            "</center>\n",
            "</body>, <center>\n",
            "<br/><br/>\n",
            "<img src=\"/static/aphrodite.gif\"/>\n",
            "<h2>Name: Aphrodite</h2>\n",
            "<br/><br/>\n",
            "Favorite animal: Dove\n",
            "<br/><br/>\n",
            "Favorite color: Red\n",
            "<br/><br/>\n",
            "Hometown: Mount Olympus\n",
            "</center>, <br/>, <br/>, <img src=\"/static/aphrodite.gif\"/>, <h2>Name: Aphrodite</h2>, <br/>, <br/>, <br/>, <br/>, <br/>, <br/>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Send a GET request to the URL of the page you want to extract content from\n",
        "response = requests.get('http://olympus.realpython.org/profiles/aphrodite')\n",
        "\n",
        "# Check the status code of the response to ensure the request was successful\n",
        "if response.status_code == 200:\n",
        "    # The request was successful\n",
        "    # Extract the content of the page\n",
        "    html_content = response.content\n",
        "else:\n",
        "    # The request was unsuccessful\n",
        "    # Handle the error\n",
        "    pass\n",
        "\n",
        "# Use the BeautifulSoup class to parse the HTML content and create a soup object\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Use the find method of the soup object to search for an element with a specific tag or attribute\n",
        "title = soup.find('title')\n",
        "\n",
        "# Extract the text of the element\n",
        "title_text = title.text\n",
        "\n",
        "# Print the text\n",
        "print(title_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8yaJTWWR9WP",
        "outputId": "3b6fa4c6-4e5d-4cfb-e9d6-576e2ca7a8e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profile: Aphrodite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# beauty_soup.py\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "\n",
        "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
        "page = urlopen(url)\n",
        "html = page.read().decode(\"utf-8\")\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "print(soup.get_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYGHhP0DV039",
        "outputId": "b8b1cdc8-2bf5-4255-8a58-e2c77e95b678"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Profile: Dionysus\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Name: Dionysus\n",
            "\n",
            "Hometown: Mount Olympus\n",
            "\n",
            "Favorite animal: Leopard \n",
            "\n",
            "Favorite Color: Wine\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find(\"img\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kccoLz3IWR14",
        "outputId": "fe0d5d2a-6753-4ada-c4ae-e32ba6be3117"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<img src=\"/static/dionysus.jpg\"/>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = soup.find(\"img\")\n",
        "# Each Tag object has a .name property that returns a string containing the HTML tag type:\n",
        "print(image1.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzGQfUqRWltP",
        "outputId": "c34dce91-bc5b-4459-871f-e92414fb0a98"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image1[\"src\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52nEAsMuXE6p",
        "outputId": "47f6d221-91cb-4c15-9c14-05dec9f4f919"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/static/dionysus.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Making a GET request\n",
        "r = requests.get('http://olympus.realpython.org/profiles/aphrodite')\n",
        "\n",
        "# Parsing the HTML\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "\n",
        "# Getting the title tag\n",
        "print(soup.title)\n",
        "\n",
        "# Getting the name of the tag\n",
        "print(soup.title.name)\n",
        "\n",
        "# Getting the name of parent tag\n",
        "print(soup.title.parent.name)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRh0VaPHIvv1",
        "outputId": "603a1d4b-f2e0-416b-d3ac-a1d18c3baa8e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<title>Profile: Aphrodite</title>\n",
            "title\n",
            "head\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Making a GET request\n",
        "r = requests.get('https://www.example.com')\n",
        "\n",
        "# Parsing the HTML\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "print(soup.find_all())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2dMRoIgJV8F",
        "outputId": "0af3264f-fed5-4f9f-e07a-269b1584b851"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<html>\n",
            "<head>\n",
            "<title>Example Domain</title>\n",
            "<meta charset=\"utf-8\"/>\n",
            "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
            "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
            "<style type=\"text/css\">\n",
            "    body {\n",
            "        background-color: #f0f0f2;\n",
            "        margin: 0;\n",
            "        padding: 0;\n",
            "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
            "        \n",
            "    }\n",
            "    div {\n",
            "        width: 600px;\n",
            "        margin: 5em auto;\n",
            "        padding: 2em;\n",
            "        background-color: #fdfdff;\n",
            "        border-radius: 0.5em;\n",
            "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
            "    }\n",
            "    a:link, a:visited {\n",
            "        color: #38488f;\n",
            "        text-decoration: none;\n",
            "    }\n",
            "    @media (max-width: 700px) {\n",
            "        div {\n",
            "            margin: 0 auto;\n",
            "            width: auto;\n",
            "        }\n",
            "    }\n",
            "    </style>\n",
            "</head>\n",
            "<body>\n",
            "<div>\n",
            "<h1>Example Domain</h1>\n",
            "<p>This domain is for use in illustrative examples in documents. You may use this\n",
            "    domain in literature without prior coordination or asking for permission.</p>\n",
            "<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
            "</div>\n",
            "</body>\n",
            "</html>, <head>\n",
            "<title>Example Domain</title>\n",
            "<meta charset=\"utf-8\"/>\n",
            "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
            "<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
            "<style type=\"text/css\">\n",
            "    body {\n",
            "        background-color: #f0f0f2;\n",
            "        margin: 0;\n",
            "        padding: 0;\n",
            "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
            "        \n",
            "    }\n",
            "    div {\n",
            "        width: 600px;\n",
            "        margin: 5em auto;\n",
            "        padding: 2em;\n",
            "        background-color: #fdfdff;\n",
            "        border-radius: 0.5em;\n",
            "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
            "    }\n",
            "    a:link, a:visited {\n",
            "        color: #38488f;\n",
            "        text-decoration: none;\n",
            "    }\n",
            "    @media (max-width: 700px) {\n",
            "        div {\n",
            "            margin: 0 auto;\n",
            "            width: auto;\n",
            "        }\n",
            "    }\n",
            "    </style>\n",
            "</head>, <title>Example Domain</title>, <meta charset=\"utf-8\"/>, <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>, <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>, <style type=\"text/css\">\n",
            "    body {\n",
            "        background-color: #f0f0f2;\n",
            "        margin: 0;\n",
            "        padding: 0;\n",
            "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
            "        \n",
            "    }\n",
            "    div {\n",
            "        width: 600px;\n",
            "        margin: 5em auto;\n",
            "        padding: 2em;\n",
            "        background-color: #fdfdff;\n",
            "        border-radius: 0.5em;\n",
            "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
            "    }\n",
            "    a:link, a:visited {\n",
            "        color: #38488f;\n",
            "        text-decoration: none;\n",
            "    }\n",
            "    @media (max-width: 700px) {\n",
            "        div {\n",
            "            margin: 0 auto;\n",
            "            width: auto;\n",
            "        }\n",
            "    }\n",
            "    </style>, <body>\n",
            "<div>\n",
            "<h1>Example Domain</h1>\n",
            "<p>This domain is for use in illustrative examples in documents. You may use this\n",
            "    domain in literature without prior coordination or asking for permission.</p>\n",
            "<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
            "</div>\n",
            "</body>, <div>\n",
            "<h1>Example Domain</h1>\n",
            "<p>This domain is for use in illustrative examples in documents. You may use this\n",
            "    domain in literature without prior coordination or asking for permission.</p>\n",
            "<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
            "</div>, <h1>Example Domain</h1>, <p>This domain is for use in illustrative examples in documents. You may use this\n",
            "    domain in literature without prior coordination or asking for permission.</p>, <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>, <a href=\"https://www.iana.org/domains/example\">More information...</a>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"------------all div paragraph\")\n",
        "s = soup.find('div')\n",
        "content = s.find_all('p')\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CzHK718GDxt",
        "outputId": "0ab1cf61-5103-4484-c40c-3dfa0c12d498"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------all div paragraph\n",
            "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
            "    domain in literature without prior coordination or asking for permission.</p>, <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Making a GET request\n",
        "r = requests.get('https://websrappingdemo.pythonanywhere.com/')\n",
        "\n",
        "# Parsing the HTML\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "\n",
        "# Finding by id\n",
        "s = soup.find('div', id= 'navDemo')\n",
        "\n",
        "# finding all\n",
        "lines = s.find_all('a', class_='w3-bar-item w3-button w3-hide-small w3-padding-large w3-hover-white')\n",
        "\n",
        "\n",
        "\n",
        "for line in lines:\n",
        "\tprint(line)\n",
        "print(\"----------------------Line text------------------------------\")\n",
        "for line in lines:\n",
        "\tprint(line.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MkfwcriJxSE",
        "outputId": "b3ea77ce-db54-4412-f491-7ec1d6b312c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a class=\"w3-bar-item w3-button w3-hide-small w3-padding-large w3-hover-white\" href=\"/enternew\">Add Student</a>\n",
            "<a class=\"w3-bar-item w3-button w3-hide-small w3-padding-large w3-hover-white\" href=\"/list\">show student List</a>\n",
            "<a class=\"w3-bar-item w3-button w3-hide-small w3-padding-large w3-hover-white\" href=\"/updatestudent\">Update student List</a>\n",
            "<a class=\"w3-bar-item w3-button w3-hide-small w3-padding-large w3-hover-white\" href=\"/del_student\">Delete Student</a>\n",
            "----------------------Line text------------------------------\n",
            "Add Student\n",
            "show student List\n",
            "Update student List\n",
            "Delete Student\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Making a GET request\n",
        "r = requests.get('https://websrappingdemo.pythonanywhere.com/')\n",
        "\n",
        "# Parsing the HTML\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "\n",
        "# Finding by id\n",
        "s = soup.find('header', class_=\"w3-container w3-blue w3-center\")\n",
        "\n",
        "print(s)\n",
        "\n",
        "h3=s.find_all(\"h3\")\n",
        "print(h3)\n",
        "\n",
        "for line in h3:\n",
        "  print(line.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "924jkKwlR_or",
        "outputId": "708cbedc-7c87-4c30-c7fe-c761bcf211b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<header class=\"w3-container w3-blue w3-center\" style=\"padding:128px 16px\">\n",
            "<h3 class=\"w3-margin w3-jumbo\">JAIN UNIVERSITY</h3>\n",
            "<h3 class=\"w3-xlarge\">ONLINE MCA PROGRAM</h3>\n",
            "<a \"=\"\" allign=\"center\" class=\"w3-button w3-black w3-padding-large w3-large w3-margin-top\" href=\"/enternew\">\n",
            "<button><center>Student Registration System</center></button></a>\n",
            "</header>\n",
            "[<h3 class=\"w3-margin w3-jumbo\">JAIN UNIVERSITY</h3>, <h3 class=\"w3-xlarge\">ONLINE MCA PROGRAM</h3>]\n",
            "JAIN UNIVERSITY\n",
            "ONLINE MCA PROGRAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Making a GET request\n",
        "r = requests.get('https://websrappingdemo.pythonanywhere.com/')\n",
        "\n",
        "# Parsing the HTML\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "\n",
        "# Finding by id\n",
        "s = soup.find('p')\n",
        "\n",
        "print(s)\n",
        "\n",
        "print(s.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAHCK4GvTHWg",
        "outputId": "9878f734-ccc9-4c1c-c86a-509fa21eae4c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<p> <center>It is web page created to understand web scrapping using python. HTML content will be extracted from this web page using request, urllib and Beautifulsoup library</center></p>\n",
            " It is web page created to understand web scrapping using python. HTML content will be extracted from this web page using request, urllib and Beautifulsoup library\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Making a GET request\n",
        "r = requests.get('http://olympus.realpython.org/profiles/aphrodite')\n",
        "\n",
        "# Parsing the HTML\n",
        "soup = BeautifulSoup(r.content, 'html.parser')\n",
        "\n",
        "images_list = []\n",
        "\n",
        "images = soup.select('img')\n",
        "for image in images:\n",
        "\tsrc = image.get('src')\n",
        "\talt = image.get('alt')\n",
        "\timages_list.append({\"src\": src, \"alt\": alt})\n",
        "\n",
        "for image in images_list:\n",
        "\tprint(image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt580UnSJ4bE",
        "outputId": "0e88498d-a82b-480f-e4f4-f48beb510ffe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': '/static/aphrodite.gif', 'alt': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Send a GET request to the URL of the page you want to extract content from\n",
        "response = requests.get('https://websrappingdemo.pythonanywhere.com/list')\n",
        "\n",
        "# Check the status code of the response to ensure the request was successful\n",
        "if response.status_code == 200:\n",
        "    # The request was successful\n",
        "    # Extract the content of the page\n",
        "    html_content = response.content\n",
        "else:\n",
        "    # The request was unsuccessful\n",
        "    # Handle the error\n",
        "    pass\n",
        "\n",
        "# Use the BeautifulSoup class to parse the HTML content and create a soup object\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Find all the table rows using the find_all method\n",
        "rows = soup.find_all('tr')\n",
        "\n",
        "# Create an empty list to store the extracted data\n",
        "data = []\n",
        "\n",
        "# Loop through each row\n",
        "for row in rows:\n",
        "    cells = row.find_all('td')\n",
        "    cell_data = []\n",
        "    for cell in cells:\n",
        "      cell_data.append(cell.text)\n",
        "\n",
        "    data.append(cell_data)\n",
        "print(data)\n",
        "# Write the data to a CSV file\n",
        "with open('data.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--mj4L9MZ6iz",
        "outputId": "a67d52ed-1f2d-4bd3-f292-9f21deb21307"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "colnames=['ID','NAME','ADDRESS','CITY', 'PINCODE']\n",
        "\n",
        "dataset = pd.read_csv(\"data.csv\", names=colnames, header=None)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEAoXg3tjuPe",
        "outputId": "0c9b0c47-4dd5-4412-c799-9843f0bfe97c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [ID, NAME, ADDRESS, CITY, PINCODE]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Send a GET request to the URL of the page you want to extract content from\n",
        "response = requests.get('https://websrappingdemo.pythonanywhere.com/list')\n",
        "\n",
        "# Check the status code of the response to ensure the request was successful\n",
        "if response.status_code == 200:\n",
        "    # The request was successful\n",
        "    # Extract the content of the page\n",
        "    html_content = response.content\n",
        "else:\n",
        "    # The request was unsuccessful\n",
        "    # Handle the error\n",
        "    pass\n",
        "\n",
        "# Use the BeautifulSoup class to parse the HTML content and create a soup object\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Find all the table rows using the find_all method\n",
        "rows = soup.find_all('tr')\n",
        "\n",
        "# Create an empty list to store the extracted data\n",
        "data = []\n",
        "\n",
        "# Loop through each row\n",
        "for row in rows:\n",
        "    # Find all the cells in the row using the find_all method\n",
        "    cells = row.find_all('td')\n",
        "\n",
        "\n",
        "    # Extract the text of each cell\n",
        "\n",
        "\n",
        "    cell_data = [cell.text for cell in cells]\n",
        "    # Add the cell data to the list of data\n",
        "\n",
        "\n",
        "\n",
        "    data.append(cell_data)\n",
        "print(data)\n",
        "# Write the data to a CSV file\n",
        "with open('data.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejzfXwEnXAUK",
        "outputId": "99604bd2-0cdd-4e87-afde-c7b96fa3a188"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[], ['3', 'wqer', 'wewe', 'we', 'ew']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "colnames=['ID','NAME','ADDRESS','CITY', 'PINCODE']\n",
        "\n",
        "dataset = pd.read_csv(\"data.csv\", names=colnames, header=None)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhpvmJClbTUh",
        "outputId": "523485a9-1c26-4903-d03a-67e7bbe2faea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID  NAME ADDRESS CITY PINCODE\n",
            "0   3  wqer    wewe   we      ew\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsmJzi4xkgkB",
        "outputId": "eb669529-ac03-45ec-d30c-fd15351757e0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Make a request to the website to get the HTML content\n",
        "url = \"https://websrappingdemo.pythonanywhere.com/list\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find the table in the HTML content\n",
        "#table = soup.find('table')\n",
        "\n",
        "# Extract the rows from the table\n",
        "rows = soup.find_all('tr')\n",
        "\n",
        "# Open a CSV file for writing\n",
        "with open('table_data.csv', 'w', newline='') as csvfile:\n",
        "    # Create a writer object\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write the header row to the CSV file\n",
        "    header_row = ['ID', 'NAME', 'address','CITY','PINCODE']\n",
        "    writer.writerow(header_row)\n",
        "\n",
        "    # For each row, extract the cells and the cell values\n",
        "    for row in rows:\n",
        "        cells = row.find_all('td')\n",
        "        cell_values = [cell.text for cell in cells]\n",
        "\n",
        "        # Write the cell values to the CSV file\n",
        "        writer.writerow(cell_values)\n"
      ],
      "metadata": {
        "id": "j53cRNHJfddY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"table_data.csv\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1obf4KPCgAks",
        "outputId": "a2f8edc5-951d-4ac5-8fad-b8e75c0e156f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID  NAME address CITY PINCODE\n",
            "0   3  wqer    wewe   we      ew\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Send a GET request to the URL of the page you want to extract content from\n",
        "response = requests.get('https://www.worldometers.info/coronavirus/#countries')\n",
        "\n",
        "# Check the status code of the response to ensure the request was successful\n",
        "if response.status_code == 200:\n",
        "    # The request was successful\n",
        "    # Extract the content of the page\n",
        "    html_content = response.content\n",
        "else:\n",
        "    # The request was unsuccessful\n",
        "    # Handle the error\n",
        "    pass\n",
        "\n",
        "# Use the BeautifulSoup class to parse the HTML content and create a soup object\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "my_table = soup.find('tbody')\n",
        "# Find all the table rows using the find_all method\n",
        "\n",
        "\n",
        "table_data = []\n",
        "for row in my_table.findAll('tr'):\n",
        "    row_data = []\n",
        "    for cell in row.findAll('td'):\n",
        "        row_data.append(cell.text)\n",
        "    if(len(row_data) > 0):\n",
        "        data_item = {\"Country\": row_data[0],\n",
        "                     \"TotalCases\": row_data[1],\n",
        "                     \"NewCases\": row_data[2],\n",
        "                     \"TotalDeaths\": row_data[3],\n",
        "                     \"NewDeaths\": row_data[4],\n",
        "                     \"TotalRecovered\": row_data[5],\n",
        "                     \"ActiveCases\": row_data[6],\n",
        "                     \"CriticalCases\": row_data[7],\n",
        "                     \"Totcase1M\": row_data[8],\n",
        "                     \"Totdeath1M\": row_data[9],\n",
        "                     \"TotalTests\": row_data[10],\n",
        "                     \"Tottest1M\": row_data[11],\n",
        "        }\n",
        "        table_data.append(data_item)"
      ],
      "metadata": {
        "id": "q2hFXBsfmGuh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset = pd.DataFrame(table_data)\n",
        "\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elp-wk_fmsfr",
        "outputId": "28dedaff-c1e9-4be6-fc75-632810d56409"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Country         TotalCases     NewCases TotalDeaths  \\\n",
            "0            \\nNorth America\\n  131,889,132               \n",
            "1                     \\nAsia\\n  221,500,265               \n",
            "2                   \\nEurope\\n  253,406,198               \n",
            "3            \\nSouth America\\n   70,200,879               \n",
            "4                  \\nOceania\\n   14,895,771               \n",
            "..      ...                ...          ...         ...   \n",
            "234     227            Tokelau           80               \n",
            "235     228       Vatican City           29               \n",
            "236     229     Western Sahara           10               \n",
            "237     230         MS Zaandam            9               \n",
            "238     231              China      503,302               \n",
            "\n",
            "                                 NewDeaths TotalRecovered  ActiveCases  \\\n",
            "0                                1,695,941                 127,665,129   \n",
            "1                                1,553,662                 205,673,091   \n",
            "2                                2,101,824                 248,754,104   \n",
            "3                                1,367,332                  66,683,585   \n",
            "4                                   33,015                  14,752,388   \n",
            "..                                     ...            ...          ...   \n",
            "234                                                                      \n",
            "235                                                                 29   \n",
            "236      1                                                           9   \n",
            "237      2                                                           7   \n",
            "238  5,272                                                     379,053   \n",
            "\n",
            "    CriticalCases   Totcase1M Totdeath1M TotalTests Tottest1M  \n",
            "0            +350   2,528,062      6,095                       \n",
            "1                  14,273,512     14,733                       \n",
            "2            +474   2,550,270      4,453                       \n",
            "3                   2,149,962      8,953                       \n",
            "4                     110,368         31                       \n",
            "..            ...         ...        ...        ...       ...  \n",
            "234                        80                58,055            \n",
            "235                         0                36,295            \n",
            "236                         0                    16         2  \n",
            "237                         0                                  \n",
            "238                   118,977        N/A        347         4  \n",
            "\n",
            "[239 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def get_data():\n",
        "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "    r = requests.get(\"https://www.example.com/products\", headers=headers)\n",
        "    content = r.content\n",
        "    soup = BeautifulSoup(content)\n",
        "\n",
        "    products = []\n",
        "    for product in soup.find_all(\"div\", class_=\"product-card\"):\n",
        "        name = product.find(\"h3\", class_=\"product-name\").text\n",
        "        price = product.find(\"span\", class_=\"product-price\").text\n",
        "        products.append([name, price])\n",
        "\n",
        "    return products\n",
        "\n",
        "def write_to_csv(data):\n",
        "    with open(\"products.csv\", \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Name\", \"Price\"])\n",
        "        writer.writerows(data)\n",
        "\n",
        "data = get_data()\n",
        "write_to_csv(data)\n"
      ],
      "metadata": {
        "id": "nStgvR9EmGHK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5NlRDYtgkiU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.ticker as ticker\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGNdgYo4hWBk"
      },
      "source": [
        "no_pages = 2\n",
        "\n",
        "def get_data(pageNo):\n",
        "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
        "\n",
        "    r = requests.get('https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_'+str(pageNo)+'?ie=UTF8&pg='+str(pageNo), headers=headers)#, proxies=proxies)\n",
        "    content = r.content\n",
        "    soup = BeautifulSoup(content)\n",
        "    #print(soup)\n",
        "\n",
        "    alls = []\n",
        "    for d in soup.findAll('div', attrs={'class':'a-section a-spacing-none aok-relative'}):\n",
        "        print(d)\n",
        "        name = d.find('span', attrs={'class':'zg-text-center-align'})\n",
        "        n = name.find_all('img', alt=True)\n",
        "        #print(n[0]['alt'])\n",
        "        author = d.find('a', attrs={'class':'a-size-small a-link-child'})\n",
        "        rating = d.find('span', attrs={'class':'a-icon-alt'})\n",
        "        users_rated = d.find('a', attrs={'class':'a-size-small a-link-normal'})\n",
        "        price = d.find('span', attrs={'class':'p13n-sc-price'})\n",
        "\n",
        "        all1=[]\n",
        "\n",
        "        if name is not None:\n",
        "            #print(n[0]['alt'])\n",
        "            all1.append(n[0]['alt'])\n",
        "        else:\n",
        "            all1.append(\"unknown-product\")\n",
        "\n",
        "        if author is not None:\n",
        "            #print(author.text)\n",
        "            all1.append(author.text)\n",
        "        elif author is None:\n",
        "            author = d.find('span', attrs={'class':'a-size-small a-color-base'})\n",
        "            if author is not None:\n",
        "                all1.append(author.text)\n",
        "            else:\n",
        "                all1.append('0')\n",
        "\n",
        "        if rating is not None:\n",
        "            #print(rating.text)\n",
        "            all1.append(rating.text)\n",
        "        else:\n",
        "            all1.append('-1')\n",
        "\n",
        "        if users_rated is not None:\n",
        "            #print(price.text)\n",
        "            all1.append(users_rated.text)\n",
        "        else:\n",
        "            all1.append('0')\n",
        "\n",
        "        if price is not None:\n",
        "            #print(price.text)\n",
        "            all1.append(price.text)\n",
        "        else:\n",
        "            all1.append('0')\n",
        "        alls.append(all1)\n",
        "    return alls"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCyjNzN2hd_S"
      },
      "source": [
        "results = []\n",
        "for i in range(1, no_pages+1):\n",
        "    results.append(get_data(i))\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "df = pd.DataFrame(flatten(results),columns=['Book Name','Author','Rating','Customers_Rated', 'Price'])\n",
        "df.to_csv('amazon_products.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiTiEbnThkID"
      },
      "source": [
        "dataset = pd.read_csv(\"amazon_products.csv\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ue_d7RiZr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01608722-326a-4a8e-879d-c6877888c51e"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY-tcUAFif_N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1bd0ded9-6db7-42f0-f075-7510860da63c"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Book Name, Author, Rating, Customers_Rated, Price]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-684777dc-7c3b-4b45-9399-93ca7a535ad3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Book Name</th>\n",
              "      <th>Author</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Customers_Rated</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-684777dc-7c3b-4b45-9399-93ca7a535ad3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-684777dc-7c3b-4b45-9399-93ca7a535ad3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-684777dc-7c3b-4b45-9399-93ca7a535ad3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_2d4e9c15-6d0e-4f6a-b283-288b8d7f633f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2d4e9c15-6d0e-4f6a-b283-288b8d7f633f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}